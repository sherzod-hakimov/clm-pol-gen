{"experiments": [{"name": "policy_with_iblip_flan_xxl_prompt_one", "game_instances": [{"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: GETS MARRIED TO GIRL OF HIS DREAMS SHE DOESN'T GIVE HEAD mame game.net\nImage Context:  a man with a sad face and caption that says he gets married to girl of his dreams she doesn't give head\n\n", "id": "8716.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage Context:  two pictures of a woman in a bathroom with a caption that says, when mama don't change diaper for 18 years\n\n", "id": "3066.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: FAP FAP FAP FAP FAP FAP memecenter Meme Center\nImage Context:  a woman in a batman costume and a woman in a thong\n\n", "id": "10861.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: imgflip.com I CAN'T BREATHE DEFUND THE OBESE!\nImage Context:  a woman sitting on a crocodile with a speech bubble saying i can't breathe\n\n", "id": "1365.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: WHEN YOU HAVEN'T UNBOXED YOUR DISHWASHER YET\nImage Context:  a woman holding a box with the words when you haven't unboxed your dishwasher yet\n\n", "id": "6046.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: WELL T TIEM BestDemotivationalPosters.com FEMALE DIGNITY And alcohol do not mix\nImage Context:  a woman is laying down on a manhole\n\n", "id": "4533.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: GET THAT SUMMER ASS flat ORIGINAL For wicked memes FOR ONLY $9.99\nImage Context:  a picture of a woman with a can of spray\n\n", "id": "10768.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: Hot girls Hot girls Cute girls Cute girls\nImage Context:  a picture of a stuffed animal with the words cute girls and hot girls\n\n", "id": "4616.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: 'Abusive' beautician 'grabbed boyfriend by his testicles and squeezed them until they bled' Comment Translated By memritv.org Ø§Ù†ØªÙ‚Ù… Let's talk about wife beating again.\nImage Context:  two women are shown in a photo with a caption\n\n", "id": "1053.jpg"}, {"game_id": 0, "prompt": "Your task is to fill in a slot that corresponds to the certain part of a hateful and misogynistic language by looking at the given sample that includes text and image context.\n\nHere are the existing slots of a hateful language: Target/Victim Identification, Attacker/Source Description, Premise/Context, Consequence/Implication, Language/Image reference.\n\nHere are the slots of a hateful language and their definitions.\nTarget/Victim Identification: Define specific attributes or characteristics that identify the target or victim of hate speech. Aspects like race, gender, religion, etc.\nAttacker/Source Description: Describe the possible source of hate speech, including characteristics or identifiers.\nPremise/Context: Outline the context in which the hate speech occurs. This could include specific scenarios, platforms, or situations.\nConsequence/Implication: State the potential impact or harm caused by the hate speech, emphasizing the seriousness of such content.\nLanguage/Image reference : State or identify spans in text that categorize a group in a negative light, and identify objects/relations from images the reinforces hate.\n\nHere are some examples and the identified slots that correspond to certain aspect of hateful language. If a certain slot is not available or too loose to connect it, simply put \"unknown\". Output the assigned slots in JSON format.\n\nText: When your mama don't change yo diaper for 19 years MENT @CHINOB4THWARD\nImage context: The image features two photos, one of which features a woman in a pair of tight pants and the other a man in a pair of jeans. The caption reads, \\\"when mama don't change for 18 years, yo\\\"\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"woman in the image\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"the context mentions a woman in tight pants and it is referred as diapers not being changed for 19 years\",\n\"Consequence/Implication\": \"the harm here is targeted towards a woman's physical appearance\",\n\"Language/Image reference\":  \"the mention of \"diapers\" and not being changed for 19 years refers to the woman in tight pants\"\n}\n\nText: MY FIANCEE DEMANDED TO KNOW IF I'D EVER BEEN WITH A PROSTITUTE. I MENTIONED HER ENGAGEMENT RING COST $2000\nImage Context:  Several people are standing near the water, with one person holding a fishing rod. The caption reads, \\\"my finance demanded to know if it had ever been with a hd - i mentored her engagement ring cost 2000\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"fiancee\",\n\"Attacker/Source Description\": \"the other engaged person\",\n\"Premise/Context\": \"it is referred to the cost of the ring ($2000) that was given for the engagement\",\n\"Consequence/Implication\": \"the harm here is targeted towards the fiancee by referring to this person as a prostitute because the engagement ring cost money and that is how the prostitute is compared to the person who received the ring that cost $2000\",\n\"Language/Image reference\":  \"the mention of the word prostitute, engagement ring cost $2000\"\n}\n\nText: People from [specific country or ethnicity] are all criminals and should be banned from our country.\nImage Context:  A cartoon depicting individuals of a certain ethnicity in a stereotypical and derogatory manner\n\nSlots from hateful language:\n{\n\"Target/Victim Identification\": \"Group/Community of [specific country or ethnicity]\",\n\"Attacker/Source Description\": \"unknown\",\n\"Premise/Context\": \"Nationalism from Attacker's perspective | Anti-immigration | Stereotype w.r.t the target\",\n\"Consequence/Implication\": \"Hurtful | Exclusion of target from society\",\n\"Language/Image reference\":  \"criminal, banned from country in text linked to cartoon behind in image context\"\n}\n\nNow, do the following for this example and fill the slots from hateful language and output the same slots with their values in JSON format:\n\nText: WOMEN Know your place\nImage Context:  a poster of two women in a kitchen\n\n", "id": "13429.jpg"}]}]}